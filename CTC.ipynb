{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils,datasets, models\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time \n",
    "import copy\n",
    "from collections import namedtuple\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WSJ_PATH\"] = '/Users/thierryhuang/Desktop/2019Spring/Deep_Learning/CTC speech learning/hw3p2-data-V2'\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class WSJ():\n",
    "    \"\"\" Load the WSJ speech dataset\n",
    "        \n",
    "        Ensure WSJ_PATH is path to directory containing \n",
    "        all data files (.npy) provided on Kaggle.\n",
    "        \n",
    "        Example usage:\n",
    "            loader = WSJ()\n",
    "            trainX, trainY = loader.train\n",
    "            assert(trainX.shape[0] == 24590)\n",
    "            \n",
    "    \"\"\"\n",
    "  \n",
    "    def __init__(self):\n",
    "        self.dev_set = None\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "  \n",
    "    @property\n",
    "    def dev(self):\n",
    "        if self.dev_set is None:\n",
    "            self.dev_set = load_raw(os.environ['WSJ_PATH'], 'wsj0_dev')\n",
    "        return self.dev_set\n",
    "    \n",
    "    os.environ[\"WSJ_PATH\"] = '/Users/thierryhuang/Desktop/2019Spring/Deep_Learning/CTC speech learning/hw3p2-data-V2'\n",
    "    @property\n",
    "    def train(self):\n",
    "        if self.train_set is None:\n",
    "            self.train_set = load_raw(os.environ['WSJ_PATH'], 'wsj0_train')\n",
    "        return self.train_set\n",
    "  \n",
    "    @property\n",
    "    def test(self):\n",
    "        if self.test_set is None:\n",
    "            self.test_set = (np.load(os.path.join(os.environ['WSJ_PATH'], 'transformed_test_data.npy'), encoding='bytes'), None)\n",
    "        return self.test_set\n",
    "    \n",
    "def load_raw(path, name):\n",
    "    return (\n",
    "        np.load(os.path.join(path, '{}.npy'.format(name)), encoding='bytes'), \n",
    "        np.load(os.path.join(path, '{}_merged_labels.npy'.format(name)), encoding='bytes')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24724"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WSJ()\n",
    "trainX, trainY = loader.train\n",
    "trainX.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, trainY = trainX[:7], trainY[:7]\n",
    "trainX.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devX, devY = loader.dev[:2]\n",
    "devX.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = loader.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 15, 16, 33, 34,  8, 26, 40, 35,  8, 28, 33, 23, 25, 42, 11, 17,\n",
       "       44, 14, 22, 41, 16, 26,  8, 32, 27,  8, 28, 37,  8, 41, 15, 23, 43,\n",
       "       40, 27,  8, 28, 25,  8, 32,  7, 34, 22, 37, 23, 19, 17, 34, 30, 35,\n",
       "        8, 26, 22, 28, 37, 33,  8, 34, 37, 36])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devY[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 40), (52,))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[1].shape,trainY[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDatasets(Dataset):\n",
    "\n",
    "    def __init__(self, data, label):\n",
    "#         self.data = data\n",
    "        self.data = data\n",
    "#         self.data = torch.tensor(data).view(-1,len(self.data))\n",
    "#         self.label = label\n",
    "        self.label= label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = torch.tensor(self.data[index]),torch.tensor((self.label[index]))\n",
    "        \n",
    "        return x,y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "trainDatasets = SpeechDatasets(trainX,trainY)\n",
    "valDatasets = SpeechDatasets(devX,devY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-9.2617, -9.6756, -9.6329,  ..., -1.9969, -2.1711, -2.7854],\n",
       "         [-9.5377, -9.5849, -8.5210,  ..., -2.3204, -1.6032, -2.2624],\n",
       "         [-8.8446, -9.2419, -8.8936,  ..., -2.4073, -2.4993, -2.6594],\n",
       "         ...,\n",
       "         [-5.2646, -5.2775, -6.3596,  ..., -3.6862, -3.9479, -4.0261],\n",
       "         [-6.4038, -5.0855, -5.0489,  ..., -3.6954, -3.3632, -4.2306],\n",
       "         [-4.8946, -4.5879, -5.1229,  ..., -3.3868, -2.9438, -3.5909]]),\n",
       " tensor([36, 15,  8, 19, 23, 27, 18, 26, 32, 33,  8, 14, 40, 34, 22, 44,  8, 26,\n",
       "         22, 37, 17,  1,  8, 41, 37, 40, 37,  8, 19,  9, 33, 43,  8, 29,  2, 22,\n",
       "         28, 28, 30, 41, 16, 27, 12, 17,  1,  7, 28, 14, 14, 22, 34, 16, 27, 12,\n",
       "         17,  0, 36]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def padding(batch):\n",
    "    # 1. Sort\n",
    "    sorted_pairs = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "    sorted_sequences = [x[0] for x in sorted_pairs]\n",
    "    \n",
    "    # 2. Pad sequence\n",
    "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sorted_sequences, batch_first=True)\n",
    "    length = torch.LongTensor([len(x) for x in sorted_sequences])\n",
    "\n",
    "    labels = [x[1]+1 for x in sorted_pairs]\n",
    "    labels_length = torch.LongTensor([len(x) for x in labels])\n",
    "    \n",
    "# #     labels = torch.LongTensor(np.array(map(lambda x: x[1], sorted_pairs)))\n",
    "#     print(sequences_padded.shape)\n",
    "# #     print(len(labels))\n",
    "#     print(length)\n",
    "# #     print(labels)\n",
    "#     print(labels_length)\n",
    "\n",
    "    return sequences_padded, length, labels, labels_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset to dataloader that handles batching\n",
    "batch_size = 3\n",
    "train_size = len(trainDatasets)\n",
    "val_size = len(valDatasets)\n",
    "# test_size = test_data.test_data.shape[0]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainDatasets, \n",
    "                                           shuffle = True,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=padding)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(valDatasets, \n",
    "                                           shuffle = True,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1106)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDatasets),len(valDatasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1478, 40]) torch.Size([559])\n",
      "tensor([37, 37, 38, 41, 29, 17, 34, 31, 21, 19, 25, 34, 19, 27, 34, 31, 15, 45,\n",
      "        20, 18, 28, 14, 12, 29,  9,  3, 17, 29, 38, 18, 16,  9, 35, 23, 38, 24,\n",
      "        20, 18, 28, 16,  9, 29, 10, 34, 39, 24, 35, 38,  9, 29, 15, 29, 10, 34,\n",
      "        39, 43, 17, 35, 38, 37, 37, 16,  9, 20, 24, 28, 19, 27, 33, 34,  9, 15,\n",
      "        41, 35, 23, 45,  9, 27, 23, 38, 18,  2,  9, 42, 38, 41, 38,  9, 20, 10,\n",
      "        34, 44,  9, 30,  3, 23, 29, 29, 31, 42, 17, 28, 13, 18,  2,  8, 29, 15,\n",
      "        15, 23, 35, 17, 28, 13, 18,  1, 37, 37,  4, 29, 41, 28, 18,  9, 35, 43,\n",
      "        18, 26, 35,  9, 42,  7, 34, 38, 37, 18, 13, 19, 35, 38,  7, 29, 16,  9,\n",
      "        35, 38, 10, 34, 24,  9, 42, 16,  9, 35,  8, 26, 34,  9, 20, 12, 35,  9,\n",
      "        42, 12, 45,  9, 26, 37, 37]) tensor([60, 57, 52])\n",
      "1\n",
      "torch.Size([1589, 40]) torch.Size([563])\n",
      "tensor([37, 37, 23, 29, 34, 24, 35,  9, 29, 38, 44, 18, 45,  2, 36, 24, 22,  9,\n",
      "        45, 33, 34, 12, 28, 17, 34,  9, 27, 24,  9, 33, 23, 34, 15, 23, 29, 38,\n",
      "        17, 27,  9, 42, 23, 46,  9, 29, 20, 23, 27, 28, 45, 35,  9, 14, 17, 45,\n",
      "        27, 23, 38,  9, 27, 21, 27, 10, 34, 24,  9,  6, 37, 37, 37, 16,  9, 33,\n",
      "        34,  7, 35, 17, 35, 13, 12, 43, 23, 14, 16,  9, 27, 17, 29, 45, 20, 31,\n",
      "        26, 23, 35, 23, 45,  7, 29, 23, 26, 35, 38, 18, 29,  9, 27,  7, 13, 25,\n",
      "        17, 26, 38, 35, 23, 45, 26, 10, 27, 15,  9, 26,  7, 28,  9, 15, 19, 36,\n",
      "         9, 29,  4, 37, 37, 16, 17, 34, 35,  9, 27, 41, 36,  9, 29, 34, 24, 26,\n",
      "        43, 12, 18, 45, 15, 23, 42, 17, 27,  9, 33, 28,  9, 29, 38,  9, 42, 16,\n",
      "        24, 22, 44, 41, 28,  9, 29, 26,  9, 33,  8, 35, 23, 38, 24, 20, 18, 35,\n",
      "        31, 36,  9, 27, 23, 29, 38, 34, 23, 35, 38,  1, 37]) tensor([67, 63, 63])\n"
     ]
    }
   ],
   "source": [
    "for index,i in enumerate(train_loader):\n",
    "    print(index)\n",
    "#     print(i)\n",
    "    x, x_lengths, label, labels_length = i\n",
    "    x_pack = torch.nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "    \n",
    "    label_pack = torch.cat(label)\n",
    "    \n",
    "    print(x_pack[0].shape,x_pack[1].shape)\n",
    "    print(label_pack,labels_length)\n",
    "    \n",
    "    if index ==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence \n",
    "\n",
    "class CTCSpeech(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CTCSpeech, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = 256\n",
    "        self.embedding_dim = 40\n",
    "        self.feature_size = 47\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = self.embedding_dim, \n",
    "                            hidden_size = self.hidden_dim, \n",
    "                            num_layers=3, \n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(self.hidden_dim * 2, self.feature_size)\n",
    "#         self.hidden = self.init_hidden()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        data, data_lengths, labels, labels_length = batch\n",
    "        x_pack = pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "        output, self.hidden = self.lstm(x_pack)\n",
    "        output = nn.utils.rnn.pad_packed_sequence(output)\n",
    "        output = self.hidden2tag(output[0])\n",
    "        \n",
    "        return output, self.hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTCSpeech(\n",
      "  (lstm): LSTM(40, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=512, out_features=47, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(CTCSpeech())\n",
    "speechmodel = CTCSpeech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CTCLoss()\n",
    "\n",
    "optimizer = optim.Adam(speechmodel.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(speechmodel.parameters(), lr = 0.001, momentum = 0.9, weight_decay = 0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, val_loader, criterion, optimizer, epochs,train_size,val_size):\n",
    "    ini_time = time.time()\n",
    "    \n",
    "    # initial weight\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # metrics record statistics\n",
    "    metrics = []\n",
    "    \n",
    "    # loop through each epoch\n",
    "    for epoch in range(epochs):\n",
    "            # set model to train model\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        \n",
    "#         scheduler.step()\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # initialize the running loss to 0\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, (batch) in enumerate(train_loader):\n",
    "            print(batch_idx)\n",
    "            if batch_idx == len(train_loader)-1:\n",
    "                break\n",
    "            \n",
    "            data, data_lengths, label, label_length  = batch\n",
    "            \n",
    "            # refresh the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "#             if batch_idx % 20000 == 0:\n",
    "#                 print(' Progress %s: %d/%d'%(epoch,batch_idx,len(train_loader)))\n",
    "#             data = data.to(device)\n",
    "#             label = label.long().to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs,hidden = model(batch)\n",
    "            outputs = outputs.log_softmax(2).detach().requires_grad_()\n",
    "            \n",
    "            label_pack = torch.cat(label)\n",
    "#             _, predicted = torch.max(outputs,1)\n",
    "#             correct += torch.sum(predicted == label)\n",
    "            print(label_pack)\n",
    "            print(label_length)\n",
    "            print(len(data_lengths))\n",
    "            loss = criterion(outputs, label_pack, data_lengths, label_length)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # accumulate loss\n",
    "            epoch_loss += loss.item() \n",
    "        \n",
    "        # end of an epoch\n",
    "        end_time = time.time()\n",
    "        print('Epoch %d Training Loss: '%(epoch+1), epoch_loss, 'Time: ',end_time - start_time, 's')\n",
    "        \n",
    "#         # print statistics\n",
    "#         total_loss = epoch_loss/train_size\n",
    "#         train_error = 1.0 - correct/train_size\n",
    "#         train_acc = correct/train_size\n",
    "        \n",
    "        \n",
    "#         # validation process\n",
    "#         val_correct = 0\n",
    "#         model.eval()\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch_idx, (val_data, val_label) in enumerate(val_loader):\n",
    "\n",
    "#                 val_data = val_data.to(device)\n",
    "#                 val_label = val_label.long().to(device)\n",
    "#                 out = model(val_data)\n",
    "#                 _, val_predicted = torch.max(out,1)\n",
    "#                 val_correct += torch.sum(val_predicted == val_label)\n",
    "                \n",
    "#             val_acc = val_correct.double() / val_size\n",
    "#             val_error = 1.0 - val_acc\n",
    "\n",
    "#             # record best weights\n",
    "#             if val_acc > best_acc:\n",
    "#                 best_acc = val_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "# #         print(\"epoch: {0}, loss: {1:.8f}\".format(epoch+1, total_loss))\n",
    "#         print(\"epoch: {0}, acc: {1:.8f}\".format(epoch+1, val_acc))\n",
    "#         metrics.append(Metric(loss=total_loss, \n",
    "#                               train_error=train_error,\n",
    "#                               val_error=val_error))\n",
    "    # end of total training\n",
    "    time_elapsed = time.time() - ini_time\n",
    "    \n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n",
      "0\n",
      "tensor([37, 37, 38, 41, 29, 17, 34, 31, 21, 19, 25, 34, 19, 27, 34, 31, 15, 45,\n",
      "        20, 18, 28, 14, 12, 29,  9,  3, 17, 29, 38, 18, 16,  9, 35, 23, 38, 24,\n",
      "        20, 18, 28, 16,  9, 29, 10, 34, 39, 24, 35, 38,  9, 29, 15, 29, 10, 34,\n",
      "        39, 43, 17, 35, 38, 37, 37, 37, 16,  9, 33, 34,  7, 35, 17, 35, 13, 12,\n",
      "        43, 23, 14, 16,  9, 27, 17, 29, 45, 20, 31, 26, 23, 35, 23, 45,  7, 29,\n",
      "        23, 26, 35, 38, 18, 29,  9, 27,  7, 13, 25, 17, 26, 38, 35, 23, 45, 26,\n",
      "        10, 27, 15,  9, 26,  7, 28,  9, 15, 19, 36,  9, 29,  4, 37, 37,  4, 29,\n",
      "        41, 28, 18,  9, 35, 43, 18, 26, 35,  9, 42,  7, 34, 38, 37, 18, 13, 19,\n",
      "        35, 38,  7, 29, 16,  9, 35, 38, 10, 34, 24,  9, 42, 16,  9, 35,  8, 26,\n",
      "        34,  9, 20, 12, 35,  9, 42, 12, 45,  9, 26, 37, 37])\n",
      "tensor([60, 63, 52])\n",
      "3\n",
      "1\n",
      "tensor([37, 22, 23, 45, 28, 31, 35, 35, 23, 21, 29, 23, 20, 23, 26,  9, 29, 38,\n",
      "        35, 12,  9, 29, 38, 23, 20, 23, 26, 33,  9, 13, 27, 23, 26, 19, 36,  9,\n",
      "        29, 45, 37, 43, 18, 35, 38,  9, 15, 24, 45,  9, 42, 13, 18, 15, 45,  4,\n",
      "         8, 29, 15,  3,  8, 29,  9, 28,  9, 27, 45,  4, 37, 37, 16,  9, 20, 24,\n",
      "        28, 19, 27, 33, 34,  9, 15, 41, 35, 23, 45,  9, 27, 23, 38, 18,  2,  9,\n",
      "        42, 38, 41, 38,  9, 20, 10, 34, 44,  9, 30,  3, 23, 29, 29, 31, 42, 17,\n",
      "        28, 13, 18,  2,  8, 29, 15, 15, 23, 35, 17, 28, 13, 18,  1, 37, 37, 16,\n",
      "        17, 34, 35,  9, 27, 41, 36,  9, 29, 34, 24, 26, 43, 12, 18, 45, 15, 23,\n",
      "        42, 17, 27,  9, 33, 28,  9, 29, 38,  9, 42, 16, 24, 22, 44, 41, 28,  9,\n",
      "        29, 26,  9, 33,  8, 35, 23, 38, 24, 20, 18, 35, 31, 36,  9, 27, 23, 29,\n",
      "        38, 34, 23, 35, 38,  1, 37])\n",
      "tensor([67, 57, 63])\n",
      "3\n",
      "2\n",
      "Epoch 1 Training Loss:  55.03649711608887 Time:  2.086099147796631 s\n",
      "Epoch 1/11\n",
      "----------\n",
      "0\n",
      "tensor([37, 37, 38, 41, 29, 17, 34, 31, 21, 19, 25, 34, 19, 27, 34, 31, 15, 45,\n",
      "        20, 18, 28, 14, 12, 29,  9,  3, 17, 29, 38, 18, 16,  9, 35, 23, 38, 24,\n",
      "        20, 18, 28, 16,  9, 29, 10, 34, 39, 24, 35, 38,  9, 29, 15, 29, 10, 34,\n",
      "        39, 43, 17, 35, 38, 37, 37, 16,  9, 20, 24, 28, 19, 27, 33, 34,  9, 15,\n",
      "        41, 35, 23, 45,  9, 27, 23, 38, 18,  2,  9, 42, 38, 41, 38,  9, 20, 10,\n",
      "        34, 44,  9, 30,  3, 23, 29, 29, 31, 42, 17, 28, 13, 18,  2,  8, 29, 15,\n",
      "        15, 23, 35, 17, 28, 13, 18,  1, 37, 37,  4, 29, 41, 28, 18,  9, 35, 43,\n",
      "        18, 26, 35,  9, 42,  7, 34, 38, 37, 18, 13, 19, 35, 38,  7, 29, 16,  9,\n",
      "        35, 38, 10, 34, 24,  9, 42, 16,  9, 35,  8, 26, 34,  9, 20, 12, 35,  9,\n",
      "        42, 12, 45,  9, 26, 37, 37])\n",
      "tensor([60, 57, 52])\n",
      "3\n",
      "1\n",
      "tensor([37, 37, 23, 29, 34, 24, 35,  9, 29, 38, 44, 18, 45,  2, 36, 24, 22,  9,\n",
      "        45, 33, 34, 12, 28, 17, 34,  9, 27, 24,  9, 33, 23, 34, 15, 23, 29, 38,\n",
      "        17, 27,  9, 42, 23, 46,  9, 29, 20, 23, 27, 28, 45, 35,  9, 14, 17, 45,\n",
      "        27, 23, 38,  9, 27, 21, 27, 10, 34, 24,  9,  6, 37, 37, 22, 23, 45, 28,\n",
      "        31, 35, 35, 23, 21, 29, 23, 20, 23, 26,  9, 29, 38, 35, 12,  9, 29, 38,\n",
      "        23, 20, 23, 26, 33,  9, 13, 27, 23, 26, 19, 36,  9, 29, 45, 37, 43, 18,\n",
      "        35, 38,  9, 15, 24, 45,  9, 42, 13, 18, 15, 45,  4,  8, 29, 15,  3,  8,\n",
      "        29,  9, 28,  9, 27, 45,  4, 37, 37, 16, 17, 34, 35,  9, 27, 41, 36,  9,\n",
      "        29, 34, 24, 26, 43, 12, 18, 45, 15, 23, 42, 17, 27,  9, 33, 28,  9, 29,\n",
      "        38,  9, 42, 16, 24, 22, 44, 41, 28,  9, 29, 26,  9, 33,  8, 35, 23, 38,\n",
      "        24, 20, 18, 35, 31, 36,  9, 27, 23, 29, 38, 34, 23, 35, 38,  1, 37])\n",
      "tensor([67, 67, 63])\n",
      "3\n",
      "2\n",
      "Epoch 2 Training Loss:  54.46996307373047 Time:  1.9573121070861816 s\n",
      "Epoch 2/11\n",
      "----------\n",
      "0\n",
      "tensor([37, 37, 16,  9, 33, 34,  7, 35, 17, 35, 13, 12, 43, 23, 14, 16,  9, 27,\n",
      "        17, 29, 45, 20, 31, 26, 23, 35, 23, 45,  7, 29, 23, 26, 35, 38, 18, 29,\n",
      "         9, 27,  7, 13, 25, 17, 26, 38, 35, 23, 45, 26, 10, 27, 15,  9, 26,  7,\n",
      "        28,  9, 15, 19, 36,  9, 29,  4, 37, 37, 22, 23, 45, 28, 31, 35, 35, 23,\n",
      "        21, 29, 23, 20, 23, 26,  9, 29, 38, 35, 12,  9, 29, 38, 23, 20, 23, 26,\n",
      "        33,  9, 13, 27, 23, 26, 19, 36,  9, 29, 45, 37, 43, 18, 35, 38,  9, 15,\n",
      "        24, 45,  9, 42, 13, 18, 15, 45,  4,  8, 29, 15,  3,  8, 29,  9, 28,  9,\n",
      "        27, 45,  4, 37, 37, 16, 17, 34, 35,  9, 27, 41, 36,  9, 29, 34, 24, 26,\n",
      "        43, 12, 18, 45, 15, 23, 42, 17, 27,  9, 33, 28,  9, 29, 38,  9, 42, 16,\n",
      "        24, 22, 44, 41, 28,  9, 29, 26,  9, 33,  8, 35, 23, 38, 24, 20, 18, 35,\n",
      "        31, 36,  9, 27, 23, 29, 38, 34, 23, 35, 38,  1, 37])\n",
      "tensor([63, 67, 63])\n",
      "3\n",
      "1\n",
      "tensor([37, 37, 38, 41, 29, 17, 34, 31, 21, 19, 25, 34, 19, 27, 34, 31, 15, 45,\n",
      "        20, 18, 28, 14, 12, 29,  9,  3, 17, 29, 38, 18, 16,  9, 35, 23, 38, 24,\n",
      "        20, 18, 28, 16,  9, 29, 10, 34, 39, 24, 35, 38,  9, 29, 15, 29, 10, 34,\n",
      "        39, 43, 17, 35, 38, 37, 37, 16,  9, 20, 24, 28, 19, 27, 33, 34,  9, 15,\n",
      "        41, 35, 23, 45,  9, 27, 23, 38, 18,  2,  9, 42, 38, 41, 38,  9, 20, 10,\n",
      "        34, 44,  9, 30,  3, 23, 29, 29, 31, 42, 17, 28, 13, 18,  2,  8, 29, 15,\n",
      "        15, 23, 35, 17, 28, 13, 18,  1, 37, 37,  4, 29, 41, 28, 18,  9, 35, 43,\n",
      "        18, 26, 35,  9, 42,  7, 34, 38, 37, 18, 13, 19, 35, 38,  7, 29, 16,  9,\n",
      "        35, 38, 10, 34, 24,  9, 42, 16,  9, 35,  8, 26, 34,  9, 20, 12, 35,  9,\n",
      "        42, 12, 45,  9, 26, 37, 37])\n",
      "tensor([60, 57, 52])\n",
      "3\n",
      "2\n",
      "Epoch 3 Training Loss:  55.03723335266113 Time:  1.9629487991333008 s\n",
      "Epoch 3/11\n",
      "----------\n",
      "0\n",
      "tensor([37, 37, 38, 41, 29, 17, 34, 31, 21, 19, 25, 34, 19, 27, 34, 31, 15, 45,\n",
      "        20, 18, 28, 14, 12, 29,  9,  3, 17, 29, 38, 18, 16,  9, 35, 23, 38, 24,\n",
      "        20, 18, 28, 16,  9, 29, 10, 34, 39, 24, 35, 38,  9, 29, 15, 29, 10, 34,\n",
      "        39, 43, 17, 35, 38, 37, 37, 37, 16,  9, 33, 34,  7, 35, 17, 35, 13, 12,\n",
      "        43, 23, 14, 16,  9, 27, 17, 29, 45, 20, 31, 26, 23, 35, 23, 45,  7, 29,\n",
      "        23, 26, 35, 38, 18, 29,  9, 27,  7, 13, 25, 17, 26, 38, 35, 23, 45, 26,\n",
      "        10, 27, 15,  9, 26,  7, 28,  9, 15, 19, 36,  9, 29,  4, 37, 37, 22, 23,\n",
      "        45, 28, 31, 35, 35, 23, 21, 29, 23, 20, 23, 26,  9, 29, 38, 35, 12,  9,\n",
      "        29, 38, 23, 20, 23, 26, 33,  9, 13, 27, 23, 26, 19, 36,  9, 29, 45, 37,\n",
      "        43, 18, 35, 38,  9, 15, 24, 45,  9, 42, 13, 18, 15, 45,  4,  8, 29, 15,\n",
      "         3,  8, 29,  9, 28,  9, 27, 45,  4, 37])\n",
      "tensor([60, 63, 67])\n",
      "3\n",
      "1\n",
      "tensor([37, 37, 23, 29, 34, 24, 35,  9, 29, 38, 44, 18, 45,  2, 36, 24, 22,  9,\n",
      "        45, 33, 34, 12, 28, 17, 34,  9, 27, 24,  9, 33, 23, 34, 15, 23, 29, 38,\n",
      "        17, 27,  9, 42, 23, 46,  9, 29, 20, 23, 27, 28, 45, 35,  9, 14, 17, 45,\n",
      "        27, 23, 38,  9, 27, 21, 27, 10, 34, 24,  9,  6, 37, 37, 16,  9, 20, 24,\n",
      "        28, 19, 27, 33, 34,  9, 15, 41, 35, 23, 45,  9, 27, 23, 38, 18,  2,  9,\n",
      "        42, 38, 41, 38,  9, 20, 10, 34, 44,  9, 30,  3, 23, 29, 29, 31, 42, 17,\n",
      "        28, 13, 18,  2,  8, 29, 15, 15, 23, 35, 17, 28, 13, 18,  1, 37, 37,  4,\n",
      "        29, 41, 28, 18,  9, 35, 43, 18, 26, 35,  9, 42,  7, 34, 38, 37, 18, 13,\n",
      "        19, 35, 38,  7, 29, 16,  9, 35, 38, 10, 34, 24,  9, 42, 16,  9, 35,  8,\n",
      "        26, 34,  9, 20, 12, 35,  9, 42, 12, 45,  9, 26, 37, 37])\n",
      "tensor([67, 57, 52])\n",
      "3\n",
      "2\n",
      "Epoch 4 Training Loss:  56.224233627319336 Time:  1.9526658058166504 s\n",
      "Epoch 4/11\n",
      "----------\n",
      "0\n",
      "tensor([37, 22, 23, 45, 28, 31, 35, 35, 23, 21, 29, 23, 20, 23, 26,  9, 29, 38,\n",
      "        35, 12,  9, 29, 38, 23, 20, 23, 26, 33,  9, 13, 27, 23, 26, 19, 36,  9,\n",
      "        29, 45, 37, 43, 18, 35, 38,  9, 15, 24, 45,  9, 42, 13, 18, 15, 45,  4,\n",
      "         8, 29, 15,  3,  8, 29,  9, 28,  9, 27, 45,  4, 37, 37, 16,  9, 20, 24,\n",
      "        28, 19, 27, 33, 34,  9, 15, 41, 35, 23, 45,  9, 27, 23, 38, 18,  2,  9,\n",
      "        42, 38, 41, 38,  9, 20, 10, 34, 44,  9, 30,  3, 23, 29, 29, 31, 42, 17,\n",
      "        28, 13, 18,  2,  8, 29, 15, 15, 23, 35, 17, 28, 13, 18,  1, 37, 37, 16,\n",
      "        17, 34, 35,  9, 27, 41, 36,  9, 29, 34, 24, 26, 43, 12, 18, 45, 15, 23,\n",
      "        42, 17, 27,  9, 33, 28,  9, 29, 38,  9, 42, 16, 24, 22, 44, 41, 28,  9,\n",
      "        29, 26,  9, 33,  8, 35, 23, 38, 24, 20, 18, 35, 31, 36,  9, 27, 23, 29,\n",
      "        38, 34, 23, 35, 38,  1, 37])\n",
      "tensor([67, 57, 63])\n",
      "3\n",
      "1\n",
      "tensor([37, 37, 23, 29, 34, 24, 35,  9, 29, 38, 44, 18, 45,  2, 36, 24, 22,  9,\n",
      "        45, 33, 34, 12, 28, 17, 34,  9, 27, 24,  9, 33, 23, 34, 15, 23, 29, 38,\n",
      "        17, 27,  9, 42, 23, 46,  9, 29, 20, 23, 27, 28, 45, 35,  9, 14, 17, 45,\n",
      "        27, 23, 38,  9, 27, 21, 27, 10, 34, 24,  9,  6, 37, 37, 37, 16,  9, 33,\n",
      "        34,  7, 35, 17, 35, 13, 12, 43, 23, 14, 16,  9, 27, 17, 29, 45, 20, 31,\n",
      "        26, 23, 35, 23, 45,  7, 29, 23, 26, 35, 38, 18, 29,  9, 27,  7, 13, 25,\n",
      "        17, 26, 38, 35, 23, 45, 26, 10, 27, 15,  9, 26,  7, 28,  9, 15, 19, 36,\n",
      "         9, 29,  4, 37, 37,  4, 29, 41, 28, 18,  9, 35, 43, 18, 26, 35,  9, 42,\n",
      "         7, 34, 38, 37, 18, 13, 19, 35, 38,  7, 29, 16,  9, 35, 38, 10, 34, 24,\n",
      "         9, 42, 16,  9, 35,  8, 26, 34,  9, 20, 12, 35,  9, 42, 12, 45,  9, 26,\n",
      "        37, 37])\n",
      "tensor([67, 63, 52])\n",
      "3\n",
      "2\n",
      "Epoch 5 Training Loss:  53.91337585449219 Time:  2.012403964996338 s\n",
      "Epoch 5/11\n",
      "----------\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([37, 37, 23, 29, 34, 24, 35,  9, 29, 38, 44, 18, 45,  2, 36, 24, 22,  9,\n",
      "        45, 33, 34, 12, 28, 17, 34,  9, 27, 24,  9, 33, 23, 34, 15, 23, 29, 38,\n",
      "        17, 27,  9, 42, 23, 46,  9, 29, 20, 23, 27, 28, 45, 35,  9, 14, 17, 45,\n",
      "        27, 23, 38,  9, 27, 21, 27, 10, 34, 24,  9,  6, 37, 37, 22, 23, 45, 28,\n",
      "        31, 35, 35, 23, 21, 29, 23, 20, 23, 26,  9, 29, 38, 35, 12,  9, 29, 38,\n",
      "        23, 20, 23, 26, 33,  9, 13, 27, 23, 26, 19, 36,  9, 29, 45, 37, 43, 18,\n",
      "        35, 38,  9, 15, 24, 45,  9, 42, 13, 18, 15, 45,  4,  8, 29, 15,  3,  8,\n",
      "        29,  9, 28,  9, 27, 45,  4, 37, 37, 16,  9, 20, 24, 28, 19, 27, 33, 34,\n",
      "         9, 15, 41, 35, 23, 45,  9, 27, 23, 38, 18,  2,  9, 42, 38, 41, 38,  9,\n",
      "        20, 10, 34, 44,  9, 30,  3, 23, 29, 29, 31, 42, 17, 28, 13, 18,  2,  8,\n",
      "        29, 15, 15, 23, 35, 17, 28, 13, 18,  1, 37])\n",
      "tensor([67, 67, 57])\n",
      "3\n",
      "1\n",
      "tensor([37, 37, 38, 41, 29, 17, 34, 31, 21, 19, 25, 34, 19, 27, 34, 31, 15, 45,\n",
      "        20, 18, 28, 14, 12, 29,  9,  3, 17, 29, 38, 18, 16,  9, 35, 23, 38, 24,\n",
      "        20, 18, 28, 16,  9, 29, 10, 34, 39, 24, 35, 38,  9, 29, 15, 29, 10, 34,\n",
      "        39, 43, 17, 35, 38, 37, 37, 16, 17, 34, 35,  9, 27, 41, 36,  9, 29, 34,\n",
      "        24, 26, 43, 12, 18, 45, 15, 23, 42, 17, 27,  9, 33, 28,  9, 29, 38,  9,\n",
      "        42, 16, 24, 22, 44, 41, 28,  9, 29, 26,  9, 33,  8, 35, 23, 38, 24, 20,\n",
      "        18, 35, 31, 36,  9, 27, 23, 29, 38, 34, 23, 35, 38,  1, 37, 37,  4, 29,\n",
      "        41, 28, 18,  9, 35, 43, 18, 26, 35,  9, 42,  7, 34, 38, 37, 18, 13, 19,\n",
      "        35, 38,  7, 29, 16,  9, 35, 38, 10, 34, 24,  9, 42, 16,  9, 35,  8, 26,\n",
      "        34,  9, 20, 12, 35,  9, 42, 12, 45,  9, 26, 37, 37])\n",
      "tensor([60, 63, 52])\n",
      "3\n",
      "2\n",
      "Epoch 6 Training Loss:  54.464948654174805 Time:  2.0521950721740723 s\n",
      "Epoch 6/11\n",
      "----------\n",
      "0\n",
      "tensor([37, 37, 16,  9, 33, 34,  7, 35, 17, 35, 13, 12, 43, 23, 14, 16,  9, 27,\n",
      "        17, 29, 45, 20, 31, 26, 23, 35, 23, 45,  7, 29, 23, 26, 35, 38, 18, 29,\n",
      "         9, 27,  7, 13, 25, 17, 26, 38, 35, 23, 45, 26, 10, 27, 15,  9, 26,  7,\n",
      "        28,  9, 15, 19, 36,  9, 29,  4, 37, 37, 22, 23, 45, 28, 31, 35, 35, 23,\n",
      "        21, 29, 23, 20, 23, 26,  9, 29, 38, 35, 12,  9, 29, 38, 23, 20, 23, 26,\n",
      "        33,  9, 13, 27, 23, 26, 19, 36,  9, 29, 45, 37, 43, 18, 35, 38,  9, 15,\n",
      "        24, 45,  9, 42, 13, 18, 15, 45,  4,  8, 29, 15,  3,  8, 29,  9, 28,  9,\n",
      "        27, 45,  4, 37, 37, 16,  9, 20, 24, 28, 19, 27, 33, 34,  9, 15, 41, 35,\n",
      "        23, 45,  9, 27, 23, 38, 18,  2,  9, 42, 38, 41, 38,  9, 20, 10, 34, 44,\n",
      "         9, 30,  3, 23, 29, 29, 31, 42, 17, 28, 13, 18,  2,  8, 29, 15, 15, 23,\n",
      "        35, 17, 28, 13, 18,  1, 37])\n",
      "tensor([63, 67, 57])\n",
      "3\n",
      "1\n",
      "tensor([37, 37, 23, 29, 34, 24, 35,  9, 29, 38, 44, 18, 45,  2, 36, 24, 22,  9,\n",
      "        45, 33, 34, 12, 28, 17, 34,  9, 27, 24,  9, 33, 23, 34, 15, 23, 29, 38,\n",
      "        17, 27,  9, 42, 23, 46,  9, 29, 20, 23, 27, 28, 45, 35,  9, 14, 17, 45,\n",
      "        27, 23, 38,  9, 27, 21, 27, 10, 34, 24,  9,  6, 37, 37, 16, 17, 34, 35,\n",
      "         9, 27, 41, 36,  9, 29, 34, 24, 26, 43, 12, 18, 45, 15, 23, 42, 17, 27,\n",
      "         9, 33, 28,  9, 29, 38,  9, 42, 16, 24, 22, 44, 41, 28,  9, 29, 26,  9,\n",
      "        33,  8, 35, 23, 38, 24, 20, 18, 35, 31, 36,  9, 27, 23, 29, 38, 34, 23,\n",
      "        35, 38,  1, 37, 37,  4, 29, 41, 28, 18,  9, 35, 43, 18, 26, 35,  9, 42,\n",
      "         7, 34, 38, 37, 18, 13, 19, 35, 38,  7, 29, 16,  9, 35, 38, 10, 34, 24,\n",
      "         9, 42, 16,  9, 35,  8, 26, 34,  9, 20, 12, 35,  9, 42, 12, 45,  9, 26,\n",
      "        37, 37])\n",
      "tensor([67, 63, 52])\n",
      "3\n",
      "2\n",
      "Epoch 7 Training Loss:  53.90909767150879 Time:  2.0257110595703125 s\n",
      "Epoch 7/11\n",
      "----------\n",
      "0\n",
      "tensor([37, 37, 23, 29, 34, 24, 35,  9, 29, 38, 44, 18, 45,  2, 36, 24, 22,  9,\n",
      "        45, 33, 34, 12, 28, 17, 34,  9, 27, 24,  9, 33, 23, 34, 15, 23, 29, 38,\n",
      "        17, 27,  9, 42, 23, 46,  9, 29, 20, 23, 27, 28, 45, 35,  9, 14, 17, 45,\n",
      "        27, 23, 38,  9, 27, 21, 27, 10, 34, 24,  9,  6, 37, 37, 16, 17, 34, 35,\n",
      "         9, 27, 41, 36,  9, 29, 34, 24, 26, 43, 12, 18, 45, 15, 23, 42, 17, 27,\n",
      "         9, 33, 28,  9, 29, 38,  9, 42, 16, 24, 22, 44, 41, 28,  9, 29, 26,  9,\n",
      "        33,  8, 35, 23, 38, 24, 20, 18, 35, 31, 36,  9, 27, 23, 29, 38, 34, 23,\n",
      "        35, 38,  1, 37, 37,  4, 29, 41, 28, 18,  9, 35, 43, 18, 26, 35,  9, 42,\n",
      "         7, 34, 38, 37, 18, 13, 19, 35, 38,  7, 29, 16,  9, 35, 38, 10, 34, 24,\n",
      "         9, 42, 16,  9, 35,  8, 26, 34,  9, 20, 12, 35,  9, 42, 12, 45,  9, 26,\n",
      "        37, 37])\n",
      "tensor([67, 63, 52])\n",
      "3\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-7eb79216fbb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeechmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-175-4e80aad01826>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, epochs, train_size, val_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-ff6adbbc7ecf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 182\u001b[0;31m                            self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model_ft = train_epoch(speechmodel, train_loader, val_loader, criterion, optimizer, 12,train_size,val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True,batch_first=True)  # <- change here\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
    "        return (torch.autograd.Variable(torch.zeros(2, 1, self.hidden_dim)),   \n",
    "                torch.autograd.Variable(torch.zeros(2, 1, self.hidden_dim)))    # <- change here: first dim of hidden needs to be doubled\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
